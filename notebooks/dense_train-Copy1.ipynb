{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/paperspace/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import keras\n",
    "import keras.applications as apps\n",
    "import numpy as np\n",
    "import os\n",
    "import densenet\n",
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    }
   ],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"/home/paperspace/test_weights/noise_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE_SIZE = 221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/keras/applications/imagenet_utils.py:258: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 2 input channels.\n",
      "  str(input_shape[-1]) + ' input channels.')\n"
     ]
    }
   ],
   "source": [
    "net = densenet.DenseNet121(include_top=True,\n",
    "                      weights=None,\n",
    "                      input_shape=(221, 221, 2),\n",
    "                      pooling=None,\n",
    "                      classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_noise =densenet.DenseNet121(include_top=True,\n",
    "                      weights=None,\n",
    "                      input_shape=(221, 221, 2),\n",
    "                      pooling=None,\n",
    "                      classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_image(HH, HV, conc, tile_size=221):\n",
    "    # This function assumes all images are the same shape\n",
    "    tile_center = tile_size//2\n",
    "    amount_x = (HH.shape[0]//tile_size) -1\n",
    "    amount_y = (HH.shape[1]//tile_size) -1\n",
    "    sar_tiles = []\n",
    "    conc_tiles = []\n",
    "    for i in range(amount_x):\n",
    "        for j in range(amount_y):\n",
    "            x_bounds = [tile_size*i, tile_size*(i+1)]\n",
    "            y_bounds = [tile_size*j, tile_size*(j+1)]\n",
    "            conc_tile = conc[x_bounds[0]:x_bounds[1], y_bounds[0]:y_bounds[1]]\n",
    "            if np.max(conc_tile) != 255:\n",
    "                HH_tile = HH[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]]\n",
    "                HV_tile = HV[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]]\n",
    "                tile = np.stack([HH_tile, HV_tile],axis=-1)\n",
    "                sar_tiles.append(tile)\n",
    "                conc_tiles.append([conc_tile[tile_center, tile_center]])\n",
    "    sar_tiles = np.asarray(sar_tiles).astype(np.float32)/255\n",
    "    conc_tiles = np.asarray(conc_tiles).astype(np.float32)/100\n",
    "    \n",
    "    return sar_tiles, conc_tiles\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_fine(HH, HV, conc, model, tile_size=221):\n",
    "\n",
    "    amount_x = ((HH.shape[0])//tile_size) -2\n",
    "    amount_y = (HH.shape[1]//tile_size) -2\n",
    "    scan_size = 2\n",
    "    conc_image = np.zeros((amount_x*(scan_size+1), amount_y*(scan_size+1)))\n",
    "    for i in tqdm.tqdm(range(amount_x)):\n",
    "        for j in range(amount_y):\n",
    "            for s in range(scan_size+1):\n",
    "                for x in range(scan_size+1):\n",
    "                    \n",
    "                    x_bounds = [int(tile_size*(i+ s/scan_size)), int(tile_size*(i+1 + s/scan_size))]\n",
    "                    y_bounds = [int(tile_size*(j + x/scan_size)), int(tile_size*(j+1 + x/scan_size))]\n",
    "                    conc_tile = conc[x_bounds[0]:x_bounds[1], y_bounds[0]:y_bounds[1]]\n",
    "                    if np.max(conc_tile) < 150:\n",
    "                        HH_tile = HH[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]]\n",
    "                        HV_tile = HV[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]]\n",
    "                        tile = np.expand_dims(np.stack([HH_tile, HV_tile],axis=-1), axis=0)\n",
    "                        tile = tile.astype(np.float32)/255\n",
    "        #                 sar_tiles.append(tile)/\n",
    "                        pred = model.predict(tile)\n",
    "                        pval = pred.flatten()[0]\n",
    "                        if pval > 1.5:\n",
    "                            pval = np.nan\n",
    "        #                 print('VAL:', pred)\n",
    "#                         conc_image[i,j] = pval\n",
    "                        conc_image[i*(scan_size+1)+s,j*(scan_size+1) + x] = pval\n",
    "                    else:\n",
    "                        conc_image[i*(scan_size+1)+s,j*(scan_size+1) + x] = np.nan\n",
    "    return conc_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(HH, HV, conc, model, tile_size=221):\n",
    "    amount_x = (HH.shape[0]//tile_size) -1\n",
    "    amount_y = (HH.shape[1]//tile_size) -1\n",
    "    conc_image = np.zeros((amount_x,amount_y))\n",
    "    sar_tiles = []\n",
    "    conc_tiles = []\n",
    "    for i in range(amount_x):\n",
    "        for j in range(amount_y):\n",
    "            x_bounds = [tile_size*i, tile_size*(i+1)]\n",
    "            y_bounds = [tile_size*j, tile_size*(j+1)]\n",
    "            conc_tile = conc[x_bounds[0]:x_bounds[1], y_bounds[0]:y_bounds[1]]\n",
    "            if np.max(conc_tile) < 150:\n",
    "                HH_tile = HH[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]]\n",
    "                HV_tile = HV[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]]\n",
    "                tile = np.expand_dims(np.stack([HH_tile, HV_tile],axis=-1), axis=0)\n",
    "                tile = tile.astype(np.float32)/255\n",
    "#                 sar_tiles.append(tile)/\n",
    "                pred = model.predict(tile)\n",
    "                pval = pred.flatten()[0]\n",
    "                if pval > 1.5:\n",
    "                    pval = np.nan\n",
    "#                 print('VAL:', pred)\n",
    "                conc_image[i,j] = pval\n",
    "                \n",
    "            else:\n",
    "                conc_image[i,j] = np.nan\n",
    "    return conc_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_data_valid(folder_path):\n",
    "    valid = os.path.exists(os.path.join(folder_path, 'imagery_HH.tif'))\n",
    "    valid = valid and os.path.exists(os.path.join(folder_path, 'imagery_HV.tif')) \n",
    "    valid = valid and os.path.exists(os.path.join(folder_path, 'conc.tiff'))\n",
    "    return valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(folder):\n",
    "    hh_image = cv.imread(os.path.join(folder, 'imagery_HH.tif'), cv.IMREAD_GRAYSCALE)\n",
    "    hv_image = cv.imread(os.path.join(folder, 'imagery_HV.tif'), cv.IMREAD_GRAYSCALE)\n",
    "    conc_image = cv.imread(os.path.join(folder, 'conc.tiff'), cv.IMREAD_GRAYSCALE)\n",
    "    return hh_image, hv_image, conc_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [f for f in glob.glob(os.path.join('training_data/20*')) if is_data_valid(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "rand_folders = sorted(folders, key=lambda f: random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_amount = len(rand_folders)//6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folders = rand_folders[:-train_amount]\n",
    "testing_folders = rand_folders[-train_amount:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tile_data(folder_name, images, labels, pos, dry_run=False, multiplier=1):\n",
    "    amount = 0\n",
    "    try:\n",
    "        SHIFT = TILE_SIZE//multiplier\n",
    "        hh_image, hv_image, conc_image = read_data(folder_name)\n",
    "        conc_image_big = cv.resize(conc_image, hh_image.shape[0:2][::-1])\n",
    "        for _ in range(multiplier):\n",
    "            hh_image = hh_image[SHIFT:, SHIFT:]\n",
    "            hv_image = hv_image[SHIFT:, SHIFT:]\n",
    "            conc_image_big = conc_image_big[SHIFT:, SHIFT:]\n",
    "            im_tiles, c_tiles = tile_image(hh_image, hv_image, conc_image_big)\n",
    "            if not dry_run:\n",
    "                images[pos+amount:pos + amount+ len(im_tiles)] = im_tiles\n",
    "                labels[pos+amount:pos + amount + len(c_tiles)] = c_tiles\n",
    "            amount = amount + len(im_tiles)\n",
    "    except:\n",
    "        print(folder_name)\n",
    "    if dry_run:\n",
    "        return amount\n",
    "    return images, labels, pos + amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2/23 [00:02<00:22,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 14/23 [00:14<00:09,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110717B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 15/23 [00:16<00:08,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20101009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 17/23 [00:16<00:05,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:24<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "train_length = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(training_folders)):\n",
    "    train_length += gen_tile_data(folder, None, None, pos=0, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_length = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(testing_folders)):\n",
    "    test_length += gen_tile_data(folder, None, None, pos=0, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = np.zeros((train_length, TILE_SIZE, TILE_SIZE, 2), dtype=np.float32)\n",
    "training_labels = np.zeros((train_length, 1), dtype=np.float32)\n",
    "\n",
    "testing_images = np.zeros((test_length, TILE_SIZE, TILE_SIZE, 2), dtype=np.float32)\n",
    "testing_labels = np.zeros((test_length, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 14/23 [00:16<00:10,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110717B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 15/23 [00:18<00:10,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20101009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 17/23 [00:19<00:06,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:27<00:00,  1.20s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(training_folders)):\n",
    "    training_images, training_labels, pos = gen_tile_data(folder, training_images, training_labels, pos)\n",
    "\n",
    "pos = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(testing_folders)):\n",
    "    testing_images, testing_labels, pos = gen_tile_data(folder, testing_images, testing_labels, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20827, 221, 221, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1888, 221, 221, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune hyper params\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "# metrics = ['accuracy']\n",
    "loss = 'mean_squared_error'\n",
    "net.compile(optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='/tmp/linear_weights_noise_redo.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loss_noise = []\n",
    "val_loss_noise = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20827 samples, validate on 1888 samples\n",
      "Epoch 1/2\n",
      "20827/20827 [==============================] - 283s 14ms/step - loss: 0.0952 - val_loss: 0.5976\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/2\n",
      "20827/20827 [==============================] - 283s 14ms/step - loss: 0.0928 - val_loss: 8.1636\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "hist = net.fit(x=training_images, y=training_labels, epochs=2, validation_data=(testing_images, testing_labels), callbacks=[checkpointer])\n",
    "hist_loss_noise += hist.history['loss']\n",
    "val_loss_noise += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(net_noise.optimizer.lr, K.get_value(net_noise.optimizer.lr)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_noise.load_weights('check.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = net.fit(x=training_images, y=training_labels, epochs=1, batch_size=32, validation_data=(testing_images, testing_labels))\n",
    "hist_loss += hist.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    hist = net.fit(x=training_images, y=training_labels, epochs=3, validation_data=(testing_images, testing_labels))\n",
    "    hist_loss += hist.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e579fd780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(val_loss_noise, label='test')\n",
    "plt.plot(hist_loss_noise, label='train')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "fig.get_axes()[0].set_ylim(0, 0.4)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_image, hv_image, conc_image = read_data(testing_folders[2])\n",
    "conc_image_big = cv.resize(conc_image, hh_image.shape[0:2][::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hh_image\n",
    "del hv_image\n",
    "del conc_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_folder in testing_folders:\n",
    "    hh_image, hv_image, conc_image = read_data(test_folder)\n",
    "    conc_image_big = cv.resize(conc_image, hh_image.shape[0:2][::-1])\n",
    "    conc = predict_image_fine(hh_image, hv_image, conc_image_big, net)\n",
    "    image_name = os.path.basename(test_folder) + \".tiff\"\n",
    "    cv.imwrite(image_name, conc)\n",
    "    print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = predict_image_fine(hh_image, hv_image, conc_image_big, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = matplotlib.colors.Normalize(vmin=0.,vmax=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(11,11))\n",
    "plt.imshow(hh_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc, norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc,norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc, norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_test = conc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_re = cv.resize(conc_test, conc_image.shape[0:2][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_re.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_re)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = conc_image == 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_conc = np.ma.masked_array(conc_image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masked_conc/100, norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image - mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = net.predict(training_images[1000:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hh_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_weights('densenet_reset_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_weights('densenet_reset_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after we have saved the network we want to predict an image and compare it to the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_images[100,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
