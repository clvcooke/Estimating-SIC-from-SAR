{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/paperspace/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import keras\n",
    "import keras.applications as apps\n",
    "import numpy as np\n",
    "import os\n",
    "import densenet\n",
    "import densenet_noise\n",
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import shutil\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network constants\n",
    "TILE_SIZE = 321\n",
    "INPUT_CHANNELS = 2 # HH, HV\n",
    "CLASSES = 1 # regression\n",
    "RANDOM_SEED = 1 # for consistency in test/train split\n",
    "TRAINING_PATH = 'training_data/20*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three networks used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/keras/applications/imagenet_utils.py:258: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 2 input channels.\n",
      "  str(input_shape[-1]) + ' input channels.')\n"
     ]
    }
   ],
   "source": [
    "# Network 1: No modifications, simple densenet\n",
    "normal_net = densenet.DenseNet121(include_top=True,\n",
    "                      weights=None,\n",
    "                      input_shape=(TILE_SIZE, TILE_SIZE, INPUT_CHANNELS),\n",
    "                      pooling=None,\n",
    "                      classes=CLASSES)\n",
    "# Network 2: Densenet with initial gaussian noise layrer \n",
    "noise_net = densenet_noise.DenseNet121(include_top=True,\n",
    "                      weights=None,\n",
    "                      input_shape=(TILE_SIZE, TILE_SIZE, INPUT_CHANNELS),\n",
    "                      pooling=None,\n",
    "                      classes=CLASSES)\n",
    "# Network 3: Normal Densenet but using weights from network 2 initially\n",
    "net = densenet.DenseNet121(include_top=True,\n",
    "                      weights=None,\n",
    "                      input_shape=(TILE_SIZE, TILE_SIZE, INPUT_CHANNELS),\n",
    "                      pooling=None,\n",
    "                      classes=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility methods to process/load images\n",
    "def is_data_valid(folder_path):\n",
    "    valid = os.path.exists(os.path.join(folder_path, 'imagery_HH.tif'))\n",
    "    valid = valid and os.path.exists(os.path.join(folder_path, 'imagery_HV.tif')) \n",
    "    valid = valid and os.path.exists(os.path.join(folder_path, 'conc.tiff'))\n",
    "    return valid\n",
    "\n",
    "def read_data(folder):\n",
    "    hh_image = cv.imread(os.path.join(folder, 'imagery_HH.tif'), cv.IMREAD_GRAYSCALE)\n",
    "    hv_image = cv.imread(os.path.join(folder, 'imagery_HV.tif'), cv.IMREAD_GRAYSCALE)\n",
    "    conc_image = cv.imread(os.path.join(folder, 'conc.tiff'), cv.IMREAD_GRAYSCALE)\n",
    "    return hh_image, hv_image, conc_image\n",
    "\n",
    "def tile_image(HH, HV, conc, tile_size=221):\n",
    "    # This function assumes all images are the same shape\n",
    "    tile_center = tile_size//2\n",
    "    amount_x = (HH.shape[0]//tile_size) -1\n",
    "    amount_y = (HH.shape[1]//tile_size) -1\n",
    "    sar_tiles = []\n",
    "    conc_tiles = []\n",
    "    for i in range(amount_x):\n",
    "        for j in range(amount_y):\n",
    "            x_bounds = [tile_size*i, tile_size*(i+1)]\n",
    "            y_bounds = [tile_size*j, tile_size*(j+1)]\n",
    "            conc_tile = conc[x_bounds[0]:x_bounds[1], y_bounds[0]:y_bounds[1]]\n",
    "            # check if the center of the tile is land or not\n",
    "            if conc_tile[tile_center, tile_center] != 255:\n",
    "                # set all values within the SAR image to by 255 if that part of the image is land\n",
    "                HH_tile = np.where(conc_tile == 255,255,HH[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]])\n",
    "                HV_tile = np.where(conc_tile == 255, 255, HV[x_bounds[0]:x_bounds[1],y_bounds[0]:y_bounds[1]])\n",
    "                tile = np.stack([HH_tile, HV_tile],axis=-1)\n",
    "                sar_tiles.append(tile)\n",
    "                conc_tiles.append([conc_tile[tile_center, tile_center]])\n",
    "    sar_tiles = np.asarray(sar_tiles).astype(np.float32)/255\n",
    "    conc_tiles = np.asarray(conc_tiles).astype(np.float32)/100\n",
    "    \n",
    "    return sar_tiles, conc_tiles\n",
    "\n",
    "def gen_tile_data(folder_name, images, labels, pos, dry_run=False, multiplier=1):\n",
    "    amount = 0\n",
    "    try:\n",
    "        SHIFT = TILE_SIZE//multiplier\n",
    "        hh_image, hv_image, conc_image = read_data(folder_name)\n",
    "        conc_image_big = cv.resize(conc_image, hh_image.shape[0:2][::-1])\n",
    "        for _ in range(multiplier):\n",
    "            hh_image = hh_image[SHIFT:, SHIFT:]\n",
    "            hv_image = hv_image[SHIFT:, SHIFT:]\n",
    "            conc_image_big = conc_image_big[SHIFT:, SHIFT:]\n",
    "            im_tiles, c_tiles = tile_image(hh_image, hv_image, conc_image_big, tile_size=TILE_SIZE)\n",
    "            if not dry_run:\n",
    "                images[pos+amount:pos + amount+ len(im_tiles)] = im_tiles\n",
    "                labels[pos+amount:pos + amount + len(c_tiles)] = c_tiles\n",
    "            amount = amount + len(im_tiles)\n",
    "    except:\n",
    "        print(folder_name)\n",
    "    if dry_run:\n",
    "        return amount\n",
    "    return images, labels, pos + amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the test/train split by randomly selecting a series of image folders for each. Images are kept independent from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [f for f in glob.glob(os.path.join('training_data/20*')) if is_data_valid(f)]\n",
    "random.seed(RANDOM_SEED)\n",
    "rand_folders = sorted(folders, key=lambda f: random.random())\n",
    "# 17% test/train split (roughly as using independent images)\n",
    "train_amount = len(rand_folders)//6\n",
    "training_folders = rand_folders[:-train_amount]\n",
    "testing_folders = rand_folders[-train_amount:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_data/20110405',\n",
       " 'training_data/20101009B',\n",
       " 'training_data/20110217',\n",
       " 'training_data/20110223']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocating arrays pre-emptively to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3/23 [00:05<00:33,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110717B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 17/23 [00:35<00:12,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:49<00:00,  2.14s/it]\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "train_length = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(training_folders)):\n",
    "    train_length += gen_tile_data(folder, None, None, pos=0, dry_run=True, multiplier=2)\n",
    "test_length = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(testing_folders)):\n",
    "    test_length += gen_tile_data(folder, None, None, pos=0, dry_run=True, multiplier=2)\n",
    "    \n",
    "training_images = np.zeros((train_length, TILE_SIZE, TILE_SIZE, 2), dtype=np.float32)\n",
    "training_labels = np.zeros((train_length, 1), dtype=np.float32)\n",
    "\n",
    "testing_images = np.zeros((test_length, TILE_SIZE, TILE_SIZE, 2), dtype=np.float32)\n",
    "testing_labels = np.zeros((test_length, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4750"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18800"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATE\n",
    "if False:\n",
    "    length = 0\n",
    "    for k, folder in enumerate(tqdm.tqdm(training_folders + testing_folders)):\n",
    "        length += gen_tile_data(folder, None, None, pos=0, dry_run=True)\n",
    "    images = np.zeros((length, TILE_SIZE, TILE_SIZE, 2), dtype=np.float32)\n",
    "    labels = np.zeros((length, 1), dtype=np.float32)\n",
    "\n",
    "    pos = 0\n",
    "    for k, folder in enumerate(tqdm.tqdm(training_folders + testing_folders)):\n",
    "        images, labels, pos = gen_tile_data(folder, images, labels, pos)\n",
    "    training_length = int(length - length//7)\n",
    "    testing_images = images[training_length:]\n",
    "    testing_labels = labels[training_length:]\n",
    "    \n",
    "    images = images[:training_length]\n",
    "    labels = labels[:training_length]\n",
    "    training_images = images\n",
    "    training_labels = labels\n",
    "#     pos = 0\n",
    "#     for k, folder in enumerate(tqdm.tqdm(testing_folders)):\n",
    "#         testing_images, testing_labels, pos = gen_tile_data(folder, testing_images, testing_labels, pos)\n",
    "# training_images = np.zeros((train_length, TILE_SIZE, TILE_SIZE, 2), dtype=np.float32)\n",
    "# training_labels = np.zeros((train_length, 1), dtype=np.float32)\n",
    "# \n",
    "# testing_images = np.zeros((test_length, TILE_SIZE, TILE_SIZE, 2), dtype=np.float32)\n",
    "# testing_labels = np.zeros((test_length, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the training data from the images and their corresponding concentration labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3/23 [00:03<00:26,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110717B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 17/23 [00:28<00:09,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/20110214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:40<00:00,  1.75s/it]\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(training_folders)):\n",
    "    training_images, training_labels, pos = gen_tile_data(folder, training_images, training_labels, pos, multiplier=2)\n",
    "\n",
    "pos = 0\n",
    "for k, folder in enumerate(tqdm.tqdm(testing_folders)):\n",
    "    testing_images, testing_labels, pos = gen_tile_data(folder, testing_images, testing_labels, pos, multiplier=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixing the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "loss = 'mean_absolute_error'\n",
    "normal_net.compile(optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights/normal_checkpoint_LARGE2.hdf5', verbose=1, save_best_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1),\n",
    "                                    cooldown=0, patience=3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loss_normal = []\n",
    "val_loss_normal = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_net.load_weights(\"weights/normal_save_LARGE2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18800/18800 [==============================] - 218s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.190503489682382"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_net.evaluate(x=training_images, y=training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_net.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4750 [==============================] - 54s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.058460242823354505"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_net.evaluate(x=testing_images, y=testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18800 samples, validate on 4750 samples\n",
      "Epoch 1/500\n",
      "18800/18800 [==============================] - 569s 30ms/step - loss: 0.0714 - val_loss: 0.1305\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13048, saving model to weights/normal_checkpoint_LARGE2.hdf5\n",
      "Epoch 2/500\n",
      "18800/18800 [==============================] - 558s 30ms/step - loss: 0.0709 - val_loss: 0.0646\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13048 to 0.06457, saving model to weights/normal_checkpoint_LARGE2.hdf5\n",
      "Epoch 3/500\n",
      "18800/18800 [==============================] - 559s 30ms/step - loss: 0.0710 - val_loss: 0.0825\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/500\n",
      "18800/18800 [==============================] - 559s 30ms/step - loss: 0.0683 - val_loss: 0.2570\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/500\n",
      "18800/18800 [==============================] - 559s 30ms/step - loss: 0.0705 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/500\n",
      "18800/18800 [==============================] - 558s 30ms/step - loss: 0.0694 - val_loss: 0.0840\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/500\n",
      "18800/18800 [==============================] - 558s 30ms/step - loss: 0.0596 - val_loss: 0.0699\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/500\n",
      " 1536/18800 [=>............................] - ETA: 7:42 - loss: 0.0530"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0413a917af6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using loop to save loss data between epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnormal_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_reducer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Using loop to save loss data between epochs\n",
    "normal_net.fit(x=training_images, y=training_labels, epochs=500, validation_data=(testing_images, testing_labels), callbacks=[checkpointer, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_net.save_weights(\"weights/normal_save_LARGE3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune hyper params\n",
    "optimizer = keras.optimizers.Adam(lr=0.003)\n",
    "# metrics = ['accuracy']\n",
    "loss = 'mean_absolute_error'\n",
    "# loss = 'mean_squared_error'\n",
    "\n",
    "noise_net.compile(optimizer, loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights/noise_checkpoint_LARGE.hdf5', verbose=1, save_best_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='loss', factor=np.sqrt(0.1),\n",
    "                                    cooldown=0, patience=3, min_lr=1e-5)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loss_noise = []\n",
    "val_loss_noise = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the server re-setting it was necessary to reload the model several times from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_net.load_weights('weights/noise_checkpoint_LARGE.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18800 samples, validate on 4750 samples\n",
      "Epoch 1/500\n",
      "18800/18800 [==============================] - 570s 30ms/step - loss: 0.1043 - val_loss: 0.1691\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16915, saving model to weights/noise_checkpoint_LARGE.hdf5\n",
      "Epoch 2/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.1023 - val_loss: 0.1832\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.1019 - val_loss: 0.1590\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16915 to 0.15895, saving model to weights/noise_checkpoint_LARGE.hdf5\n",
      "Epoch 4/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0996 - val_loss: 0.1328\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15895 to 0.13279, saving model to weights/noise_checkpoint_LARGE.hdf5\n",
      "Epoch 5/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.1003 - val_loss: 0.1781\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0990 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0975 - val_loss: 0.1959\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0959 - val_loss: 0.1692\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/500\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0980 - val_loss: 0.1303\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13279 to 0.13030, saving model to weights/noise_checkpoint_LARGE.hdf5\n",
      "Epoch 10/500\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0977 - val_loss: 0.1577\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/500\n",
      "  352/18800 [..............................] - ETA: 8:20 - loss: 0.1002"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ede264062f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_reducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhist_loss_noise\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_loss_noise\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = noise_net.fit(x=training_images, y=training_labels, epochs=500, validation_data=(testing_images, testing_labels), callbacks=[checkpointer, lr_reducer, tensorboard])\n",
    "hist_loss_noise += hist.history['loss']\n",
    "val_loss_noise += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18800 samples, validate on 4750 samples\n",
      "Epoch 1/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0747 - val_loss: 0.1047\n",
      "\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 2/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0773 - val_loss: 0.1962\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0784 - val_loss: 0.1218\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0757 - val_loss: 0.0837\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0750 - val_loss: 0.0883\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0673 - val_loss: 0.1040\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0664 - val_loss: 0.0852\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0658 - val_loss: 0.0772\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.07784 to 0.07723, saving model to weights/noise_checkpoint_LARGE.hdf5\n",
      "Epoch 9/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0651 - val_loss: 0.0819\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0655 - val_loss: 0.0789\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0647 - val_loss: 0.0942\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0649 - val_loss: 0.0944\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0640 - val_loss: 0.0818\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0641 - val_loss: 0.0789\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0631 - val_loss: 0.0823\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0611 - val_loss: 0.0886\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0626 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0615 - val_loss: 0.0769\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07723 to 0.07695, saving model to weights/noise_checkpoint_LARGE.hdf5\n",
      "Epoch 19/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0620 - val_loss: 0.0988\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/500\n",
      "18800/18800 [==============================] - 562s 30ms/step - loss: 0.0613 - val_loss: 0.0869\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0587 - val_loss: 0.0782\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/500\n",
      "18800/18800 [==============================] - 563s 30ms/step - loss: 0.0593 - val_loss: 0.0819\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/500\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0586 - val_loss: 0.0805\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0584 - val_loss: 0.0785\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0584 - val_loss: 0.0811\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0577 - val_loss: 0.0816\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0575 - val_loss: 0.0840\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0581 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0579 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0570 - val_loss: 0.0947\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0566 - val_loss: 0.0947\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0569 - val_loss: 0.0982\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0577 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0568 - val_loss: 0.0839\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0564 - val_loss: 0.0896\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0572 - val_loss: 0.0827\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0566 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0575 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0567 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0561 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0552 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0548 - val_loss: 0.0834\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0554 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0550 - val_loss: 0.0820\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0552 - val_loss: 0.0869\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0550 - val_loss: 0.0830\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0553 - val_loss: 0.0825\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0546 - val_loss: 0.0830\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0551 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0547 - val_loss: 0.0839\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 51/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0541 - val_loss: 0.0848\n",
      "\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 52/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0545 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0546 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 54/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0552 - val_loss: 0.0864\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0545 - val_loss: 0.0857\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0542 - val_loss: 0.0835\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0542 - val_loss: 0.0833\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0547 - val_loss: 0.0840\n",
      "\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 59/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0538 - val_loss: 0.0831\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0546 - val_loss: 0.0837\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0541 - val_loss: 0.0841\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0544 - val_loss: 0.0831\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0549 - val_loss: 0.0842\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/500\n",
      "18800/18800 [==============================] - 560s 30ms/step - loss: 0.0545 - val_loss: 0.0835\n",
      "\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 65/500\n",
      "18784/18800 [============================>.] - ETA: 0s - loss: 0.0541"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ede264062f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_reducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhist_loss_noise\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_loss_noise\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1247\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1248\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                                                        verbose=0)\n\u001b[0m\u001b[1;32m   1250\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = noise_net.fit(x=training_images, y=training_labels, epochs=500, validation_data=(testing_images, testing_labels), callbacks=[checkpointer, lr_reducer, tensorboard])\n",
    "hist_loss_noise += hist.history['loss']\n",
    "val_loss_noise += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcbff7848d0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcbff784128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(noise_net.history.history['loss'])\n",
    "plt.plot(noise_net.history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.get_value(noise_net.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.27690693216120943,\n",
       "  0.22891299950315597,\n",
       "  0.21275840824588815,\n",
       "  0.20683300902234747,\n",
       "  0.20170738308987718,\n",
       "  0.19195369956341196,\n",
       "  0.1812702253714521,\n",
       "  0.17437229742395116,\n",
       "  0.16962746355761874,\n",
       "  0.16233846361332752,\n",
       "  0.16244656070115718,\n",
       "  0.15376873601624305,\n",
       "  0.15049467407642528,\n",
       "  0.1494616837641026,\n",
       "  0.14714463731709948,\n",
       "  0.14680250650390667,\n",
       "  0.14234559444670983,\n",
       "  0.13785344129547158,\n",
       "  0.13862093856994143,\n",
       "  0.13681516766389634,\n",
       "  0.13327388335415657,\n",
       "  0.1318319777478563,\n",
       "  0.13120414967232563,\n",
       "  0.12580060865650786,\n",
       "  0.1252435976520498],\n",
       " 'lr': [0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003,\n",
       "  0.003],\n",
       " 'val_loss': [0.2090218936267652,\n",
       "  0.23661759085639528,\n",
       "  0.43058590215130854,\n",
       "  0.44555508590999404,\n",
       "  0.186570525112905,\n",
       "  0.2507457503268593,\n",
       "  0.1020543137602508,\n",
       "  0.10842559804198773,\n",
       "  0.09368139724041286,\n",
       "  0.09564991132522885,\n",
       "  0.2538644316980713,\n",
       "  0.13258101244506082,\n",
       "  0.13278767383098602,\n",
       "  0.09764528105290313,\n",
       "  0.10051137783417577,\n",
       "  0.1651900686364817,\n",
       "  0.1726585044762806,\n",
       "  0.20336915002449563,\n",
       "  0.09396707709035591,\n",
       "  0.08714533263131193,\n",
       "  0.09831164272913807,\n",
       "  0.0799515812722476,\n",
       "  0.0959747499984346,\n",
       "  0.09682025500308526,\n",
       "  0.1278883077408138]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_net.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_value(optimizer.lr,0.003/np.sqrt(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.get_value(optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_net.save_weights('weights/noise_FINAL.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_weights('weights/noise_checkpoint_LARGE.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights/net_checkpoint_FINAL_LARGE.hdf5', verbose=1, save_best_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1),\n",
    "                                    cooldown=0, patience=3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune hyper params\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "# metrics = ['accuracy']\n",
    "loss = 'mean_absolute_error'\n",
    "# loss = 'mean_squared_error'\n",
    "\n",
    "net.compile(optimizer, loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18800 samples, validate on 4750 samples\n",
      "Epoch 1/15\n",
      "18800/18800 [==============================] - 578s 31ms/step - loss: 0.0642 - val_loss: 0.0879\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08791, saving model to weights/net_checkpoint_FINAL_LARGE.hdf5\n",
      "Epoch 2/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0572 - val_loss: 0.0974\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0556 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0540 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08791 to 0.08745, saving model to weights/net_checkpoint_FINAL_LARGE.hdf5\n",
      "Epoch 5/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0534 - val_loss: 0.0803\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08745 to 0.08034, saving model to weights/net_checkpoint_FINAL_LARGE.hdf5\n",
      "Epoch 6/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0520 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0524 - val_loss: 0.0787\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08034 to 0.07866, saving model to weights/net_checkpoint_FINAL_LARGE.hdf5\n",
      "Epoch 8/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0528 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0525 - val_loss: 0.0865\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0517 - val_loss: 0.0796\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0513 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0513 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0518 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0518 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/15\n",
      "18800/18800 [==============================] - 561s 30ms/step - loss: 0.0508 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hist_loss_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-98b5b2130adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_reducer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist_loss_noise\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_loss_noise\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist_loss_noise' is not defined"
     ]
    }
   ],
   "source": [
    "hist = net.fit(x=training_images, y=training_labels, epochs=15, validation_data=(testing_images, testing_labels), callbacks=[checkpointer, lr_reducer])\n",
    "hist_loss_noise += hist.history['loss']\n",
    "val_loss_noise += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_value(optimizer.lr,0.00005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.get_value(optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(val_loss_noise, label='test')\n",
    "plt.plot(hist_loss_noise, label='train')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "fig.get_axes()[0].set_ylim(0, 0.2)\n",
    "plt.grid()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.power(val_loss_noise,2), label='test')\n",
    "plt.plot(np.power(hist_loss_noise,2), label='train')\n",
    "plt.ylabel('SMAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "fig.get_axes()[0].set_ylim(0, 0.2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights/noisy_SAR_DENSE.h5'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy2('weights/noise_checkpoint.hdf5', 'weights/noisy_SAR_DENSE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noise_weights_absssss.hdf5',\n",
       " 'weights.hdf5',\n",
       " 'noise_weights_undo.hdf5',\n",
       " 'noise_weights_abs2222.hdf5',\n",
       " 'densenet_reset_v1.h5',\n",
       " 'noise_weights.hdf5',\n",
       " 'noise_weights_rand1.hdf5',\n",
       " 'noise_weights_abs222244.hdf5',\n",
       " 'noise_weights_abs.hdf5',\n",
       " 'noisy_SAR_DENSE.h5',\n",
       " 'noise_checkpoint.hdf5',\n",
       " 'noise_weights_undo_2.hdf5',\n",
       " 'noise_weights_temp.hdf5',\n",
       " 'noise_weights_abs22.hdf5']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('weights/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " K.get_value(net.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(net.optimizer.lr, K.get_value(net.optimizer.lr)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_noise.load_weights('check.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss += hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = net.fit(x=training_images, y=training_labels, epochs=1, batch_size=32, validation_data=(testing_images, testing_labels))\n",
    "hist_loss += hist.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    hist = net.fit(x=training_images, y=training_labels, epochs=3, validation_data=(testing_images, testing_labels))\n",
    "    hist_loss += hist.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(val_loss_noise, label='test')\n",
    "plt.plot(hist_loss_noise, label='train')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "# fig.get_axes()[0].set_ylim(0, 0.1)\n",
    "plt.grid()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.power(val_loss_noise,2), label='test')\n",
    "plt.plot(np.power(hist_loss_noise,2), label='train')\n",
    "plt.ylabel('SMAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "# fig.get_axes()[0].set_ylim(0, 0.1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_image, hv_image, conc_image = read_data(testing_folders[2])\n",
    "conc_image_big = cv.resize(conc_image, hh_image.shape[0:2][::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hh_image\n",
    "del hv_image\n",
    "del conc_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_folder in testing_folders:\n",
    "    hh_image, hv_image, conc_image = read_data(test_folder)\n",
    "    conc_image_big = cv.resize(conc_image, hh_image.shape[0:2][::-1])\n",
    "    conc = predict_image_fine(hh_image, hv_image, conc_image_big, net)\n",
    "    image_name = os.path.basename(test_folder) + \".tiff\"\n",
    "    cv.imwrite(image_name, conc)\n",
    "    print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = predict_image_fine(hh_image, hv_image, conc_image_big, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = matplotlib.colors.Normalize(vmin=0.,vmax=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(11,11))\n",
    "plt.imshow(hh_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc, norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc,norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc, norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_test = conc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_re = cv.resize(conc_test, conc_image.shape[0:2][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_re.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_re)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = conc_image == 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_conc = np.ma.masked_array(conc_image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masked_conc/100, norm=n)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image - mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conc_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = net.predict(training_images[1000:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hh_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_weights('densenet_reset_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_weights('densenet_reset_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after we have saved the network we want to predict an image and compare it to the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training_images[100,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
